{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMy27VA9pQKp2NBrI93/FF0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praffuln/generative-ai/blob/master/rag/rag-1/rag_indexing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "v5Ajnmz8ZfEJ",
        "outputId": "e3b98e10-d607-422f-af73-62c073f49273",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello world!!\n"
          ]
        }
      ],
      "source": [
        "print('hello world!!')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Indexing"
      ],
      "metadata": {
        "id": "lJre_8n7aV1f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-representation Indexing"
      ],
      "metadata": {
        "id": "xR6JWQW2gLvV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Enviornment**"
      ],
      "metadata": {
        "id": "D8Wf0z9wRDM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain-chroma langchain youtube-transcript-api pytube google-generativeai langchain_google_genai langchain_community"
      ],
      "metadata": {
        "id": "AekDM0f7Q_r-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Setup Keys For GOOGLE_API_KEY AND LANGSMITH"
      ],
      "metadata": {
        "id": "tzaWEi7vRMJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning value to variable\n",
        "GOOGLE_API_KEY=''\n",
        "LANGCHAIN_API_KEY = ''"
      ],
      "metadata": {
        "id": "dvFOprifTZNj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports os, google Gemini EMbedding and Chat Classes with FAISS vectorstores"
      ],
      "metadata": {
        "id": "uoqtF2Z2N8P6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n"
      ],
      "metadata": {
        "id": "ALaWrOJvc3Qe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# setup langsmith for tracing"
      ],
      "metadata": {
        "id": "6Y_EPIyLOH0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
        "os.environ['LANGCHAIN_API_KEY'] = LANGCHAIN_API_KEY\n",
        "os.environ['GOOGLE_API_KEY'] = GOOGLE_API_KEY"
      ],
      "metadata": {
        "id": "NSYmU7-pb0wM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize LLM And Embedding"
      ],
      "metadata": {
        "id": "qvscJ6UAjmHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM with function call\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.3)\n",
        "\n",
        "# Create embeddings using a Google Generative AI model\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "\n"
      ],
      "metadata": {
        "id": "mGgzDqI3jq0f"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fetch the documents"
      ],
      "metadata": {
        "id": "3FqwXYGVj5FT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
        "docs = loader.load()\n",
        "\n",
        "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2024-02-05-human-data-quality/\")\n",
        "docs.extend(loader.load())\n",
        "\n",
        "print(len(docs))\n",
        "print('\\nprinting metadata...\\n')\n",
        "for doc in docs:\n",
        "  print(doc.metadata)\n",
        "\n"
      ],
      "metadata": {
        "id": "aeNPRO6Hj7Mt",
        "outputId": "04d42939-9619-4e1e-8e3f-c4eefad01b87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "\n",
            "printing metadata...\n",
            "\n",
            "{'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}\n",
            "{'source': 'https://lilianweng.github.io/posts/2024-02-05-human-data-quality/', 'title': \"Thinking about High-Quality Human Data | Lil'Log\", 'description': '[Special thank you to Ian Kivlichan for many useful pointers (E.g. the 100+ year old Nature paper “Vox populi”) and nice feedback. \\uf8ffüôè ]\\nHigh-quality data is the fuel for modern data deep learning model training. Most of the task-specific labeled data comes from human annotation, such as classification task or RLHF labeling (which can be constructed as classification format) for LLM alignment training. Lots of ML techniques in the post can help with data quality, but fundamentally human data collection involves attention to details and careful execution.', 'language': 'en'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chain = (\n",
        "    {\"doc\": lambda x: x.page_content}\n",
        "    | ChatPromptTemplate.from_template(\"Summarize the following document:\\n\\n{doc}\")\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "summaries = chain.batch(docs, {\"max_concurrency\": 5})\n",
        "\n",
        "len(summaries)\n",
        "for summary in summaries:\n",
        "  print(summary)\n",
        "  print('\\n\\n\\n\\n\\n\\n\\n')"
      ],
      "metadata": {
        "id": "mEOwdVKGl379"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Store summary in vectorstore and original Docs in byteStore"
      ],
      "metadata": {
        "id": "DDihvnMooLl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.storage import InMemoryByteStore\n",
        "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
        "from langchain_chroma import Chroma\n",
        "\n",
        "# The vectorstore to use to index the child chunks\n",
        "vectorstore = Chroma(collection_name=\"summaries\",\n",
        "                     embedding_function=embeddings)\n",
        "\n",
        "# The storage layer for the parent documents\n",
        "store = InMemoryByteStore()\n",
        "id_key = \"doc_id\"\n",
        "\n",
        "# The retriever\n",
        "retriever = MultiVectorRetriever(\n",
        "    vectorstore=vectorstore,\n",
        "    byte_store=store,\n",
        "    id_key=id_key,\n",
        ")\n",
        "doc_ids = [str(uuid.uuid4()) for _ in docs]\n",
        "\n",
        "# Docs linked to summaries\n",
        "summary_docs = [\n",
        "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
        "    for i, s in enumerate(summaries)\n",
        "]\n",
        "\n",
        "\n",
        "summary_docs"
      ],
      "metadata": {
        "id": "iXQnXkN-oOi2",
        "outputId": "f9c8bf59-03e3-42aa-f020-7149b424f44d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'doc_id': '9d570c6f-5a6f-4478-b18f-c8131a41d52b'}, page_content='This document explores the concept of LLM-powered autonomous agents, which are systems using large language models (LLMs) as their core controllers. It breaks down the key components of such agents: planning, memory, and tool use.\\n\\n**Planning** involves breaking down complex tasks into smaller subgoals and reflecting on past actions to improve future performance. Techniques like Chain of Thought (CoT), Tree of Thoughts, and ReAct are discussed for task decomposition and self-reflection.\\n\\n**Memory** encompasses short-term memory (in-context learning) and long-term memory (external vector stores). The document delves into the concept of Maximum Inner Product Search (MIPS) and various algorithms like LSH, ANNOY, HNSW, FAISS, and ScaNN for fast retrieval from vector stores.\\n\\n**Tool Use** equips LLMs with the ability to interact with external APIs and tools. Examples like MRKL, TALM, Toolformer, ChatGPT Plugins, OpenAI API function calling, and HuggingGPT are presented, showcasing how LLMs can leverage external resources to enhance their capabilities.\\n\\nThe document also discusses case studies like ChemCrow (a scientific discovery agent) and Generative Agents (a simulation of virtual characters interacting in a sandbox environment). It highlights proof-of-concept examples like AutoGPT and GPT-Engineer, which demonstrate the potential of LLMs for automating tasks and generating code.\\n\\nFinally, the document acknowledges challenges associated with LLM-powered agents, including finite context length, difficulties in long-term planning, and the reliability of natural language interfaces. It concludes by emphasizing the ongoing research and development in this field, aiming to overcome these limitations and unlock the full potential of autonomous agents powered by LLMs.\\n'),\n",
              " Document(metadata={'doc_id': '9664a615-8ee1-4e1d-9f8b-12416ae95ff6'}, page_content='This document explores the importance of high-quality human data in deep learning model training, focusing on the challenges and opportunities associated with collecting, evaluating, and utilizing human annotations. \\n\\n**Key Takeaways:**\\n\\n* **Human data quality is crucial:**  The document emphasizes that high-quality human data is essential for training effective deep learning models, particularly in tasks involving classification and reinforcement learning from human feedback (RLHF).\\n* **The \"wisdom of the crowd\" has limitations:** While crowdsourcing can be cost-effective, it\\'s important to be aware of potential issues like spammers and the need for careful weighting schemes to ensure data quality.\\n* **Rater agreement is a complex issue:**  The document discusses various methods for measuring rater agreement, including majority voting, Cohen\\'s Kappa, and probabilistic graph modeling. It highlights the importance of addressing rater disagreement, particularly in subjective tasks where multiple interpretations may be valid.\\n* **Two contrasting paradigms for data annotation:**  The document presents two paradigms for data annotation: descriptive (embracing subjectivity) and prescriptive (encouraging consistency). It argues that the choice of paradigm depends on the specific task and desired outcome.\\n* **Data quality can be assessed during model training:**  The document explores methods for identifying mislabeled data during model training, including influence functions, prediction changes during training, and noisy cross-validation.\\n\\n**Key Methods and Techniques:**\\n\\n* **Influence functions:**  A technique for measuring the impact of individual data points on model parameters and loss function.\\n* **Data Maps:**  A method for tracking model confidence and variability during training to identify potentially mislabeled data.\\n* **AUM (Area under the Margin):**  A method for identifying mislabeled data by analyzing the margin between the assigned logit and the next largest logit during training.\\n* **NCV (Noisy Cross-Validation):**  A method for identifying clean data samples by comparing predictions from models trained on different subsets of the data.\\n\\n**Overall, the document provides a comprehensive overview of the challenges and opportunities associated with high-quality human data in deep learning. It highlights the importance of careful task design, rater selection and training, and the use of various techniques for evaluating and improving data quality.** \\n')]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add\n",
        "retriever.vectorstore.add_documents(summary_docs)\n",
        "retriever.docstore.mset(list(zip(doc_ids, docs)))"
      ],
      "metadata": {
        "id": "ORkmxiDWpKLy"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrive documents"
      ],
      "metadata": {
        "id": "knvYSb8Isvj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Get similarity search\n",
        "\n",
        "query = \"Memory in agents\"\n",
        "sub_docs = vectorstore.similarity_search(query,k=1)\n",
        "sub_docs[0]\n"
      ],
      "metadata": {
        "id": "I_OvfvpYsuuN",
        "outputId": "bc144730-5b3b-4e49-c733-f7200cfff120",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'doc_id': 'c97f0a47-9843-44e2-af16-82ee4f19f65c'}, page_content='This document explores the concept of LLM-powered autonomous agents, which are systems using large language models (LLMs) as their core controllers. It breaks down the key components of such agents: planning, memory, and tool use.\\n\\n**Planning** involves breaking down complex tasks into smaller subgoals and reflecting on past actions to improve future performance. Techniques like Chain of Thought (CoT), Tree of Thoughts, and ReAct are discussed for task decomposition and self-reflection.\\n\\n**Memory** encompasses short-term memory (in-context learning) and long-term memory (external vector stores). The document delves into the concept of Maximum Inner Product Search (MIPS) and various algorithms like LSH, ANNOY, HNSW, FAISS, and ScaNN for fast retrieval from vector stores.\\n\\n**Tool Use** equips LLMs with the ability to interact with external APIs and tools. Examples like MRKL, TALM, Toolformer, ChatGPT Plugins, OpenAI API function calling, and HuggingGPT are presented, showcasing how LLMs can leverage external resources to enhance their capabilities.\\n\\nThe document also discusses case studies like ChemCrow (a scientific discovery agent) and Generative Agents (a simulation of virtual characters interacting in a sandbox environment). It highlights proof-of-concept examples like AutoGPT and GPT-Engineer, which demonstrate the potential of LLMs for automating tasks and generating code.\\n\\nFinally, the document acknowledges challenges associated with LLM-powered agents, including finite context length, difficulties in long-term planning, and the reliability of natural language interfaces. It concludes by emphasizing the ongoing research and development in this field, aiming to overcome these limitations and unlock the full potential of autonomous agents powered by LLMs.\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Get complete document\n",
        "\n",
        "retrieved_docs = retriever.get_relevant_documents(query,n_results=1)\n",
        "retrieved_docs[0].page_content[0:500]\n"
      ],
      "metadata": {
        "id": "1SZJ4xegs5dy",
        "outputId": "719710fb-13a7-4944-a213-9953e5031d75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\n\\n\\n\\n\\nLLM Powered Autonomous Agents | Lil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\nemojisearch.app\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAPTOR"
      ],
      "metadata": {
        "id": "OgWlzFNOtpA_"
      }
    }
  ]
}