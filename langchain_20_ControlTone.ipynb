{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMILNHqAU4SM9peuzMQJYOB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praffuln/langchain/blob/master/langchain_20_ControlTone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google AI chat models\n"
      ],
      "metadata": {
        "id": "qZIQ2XVoYUdg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWhZ9dCoWBVk"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install openAI\n",
        "!pip install wikipedia\n",
        "!pip install huggingface_hub\n",
        "!pip install InstructorEmbedding\n",
        "!pip install google-search-results\n",
        "!pip install unstructured\n",
        "!pip install libmagic\n",
        "!pip install python-magic\n",
        "!pip install python-magic-bin\n",
        "#Install faiss Packages\n",
        "!pip install faiss-cpu\n",
        "!pip install sentence-transformers\n",
        "!pip install wolframalpha\n",
        "!pip install pypdf\n",
        "!pip install youtube-transcript-api\n",
        "!pip install pytube\n",
        "!pip install python-dotenv\n",
        "!pip install pinecone-client\n",
        "!pip install kor\n",
        "!pip install markdownify\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google AI chat models\n"
      ],
      "metadata": {
        "id": "DS1V9IWLAeTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cEVJZkoPAtdu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# API KEY"
      ],
      "metadata": {
        "id": "q_tUFWn6YZ7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GOOGLE_API_KEY\"] = ''\n",
        "\n",
        "# Replace these values with your own Twitter API credentials\n",
        "TWITTER_API_KEY = ''\n",
        "TWITTER_API_KEY_SECRET = ''\n",
        "TWITTER_ACCESS_TOKEN = ''\n",
        "TWITTER_ACCESS_TOKEN_SECRET = ''\n",
        "\n"
      ],
      "metadata": {
        "id": "Zau9M0-eYcSD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
        "result = llm.invoke(\"Write a ballad about LangChain\")\n",
        "print(result)\n",
        "print(result.content)\n",
        "\n"
      ],
      "metadata": {
        "id": "oxMvrCL-BA3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instructing LLMs To Match Tone\n",
        "\n",
        "LLMs that generate text are awesome, but what if you want to edit the tone/style it responds with?\n",
        "\n",
        "We've all seen the pirate examples, but it would be awesome if we could tune the prompt to match the tone of specific people?\n",
        "\n",
        "Below is a series of techniques aimed to generate text in the tone and style you want. No single technique will likely be exactly what you need, but I guarantee you can iterate with these tips to get a solid outcome for your project.\n",
        "\n",
        "But Greg, what about fine tuning? Fine tuning would likely give you a fabulous result, but the barriers to entry are too high for the average developer (as of May '23). I would rather get the 87% solution today rather than not ship something. If you're doing this in production and your differentiator is your ability to adapt to different styles you'll likely want to explore fine tuning.\n",
        "\n",
        "If you want to see a demo video of this, check out the Twitter post. For a full explination head over to YouTube.\n",
        "\n",
        "4 Levels Of Tone Matching Techniques:\n",
        "\n",
        "**Simple**: As a human, try and describe the tone you would like\n",
        "\n",
        "**Intermediate**: Include your description + examples\n",
        "\n",
        "**AI-Assisted**: Ask the LLM to extract tone, use their output in your next prompt\n",
        "\n",
        "**Technique Fusion**: Combine multiple techniques to mimic tone\n",
        "\n",
        "**Today's Goal**: Generate tweets mimicking the style of online personalities. You could customize this code to generate emails, chat messages, writing, etc.\n",
        "\n",
        "First let's import our packages\n",
        "\n"
      ],
      "metadata": {
        "id": "7gD-Ydj5recC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LangChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "# Environment Variables\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Twitter\n",
        "import tweepy\n",
        "\n",
        "load_dotenv()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqsPKrESr1rG",
        "outputId": "19224c27-6bc5-4ed6-91c0-b0cd24dea02a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method #1: Simple - Describe the tone you would like\n",
        "Our first method is going to be simply describing the tone we would like.\n",
        "\n",
        "Let's try a few exmaples\n",
        "\n"
      ],
      "metadata": {
        "id": "8DgaX_nEsAlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Please create me a tweet about going to the park and eating a sandwich.\n",
        "\"\"\"\n",
        "\n",
        "output = llm.predict(prompt)\n",
        "print (output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "IIbnJeiBsCpr",
        "outputId": "c7e87c8f-d6e1-47ca-8f86-171921ba9642"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enjoying a beautiful day at the park with a delicious sandwich in hand. The sun is shining, the birds are singing, and the sandwich is to die for. #ParkLife #SandwichLove #PerfectDay\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not bad, but I don't love the emojis and I want it to use more conversational modern language.\n",
        "\n",
        "Let's try again\n",
        "\n"
      ],
      "metadata": {
        "id": "zCMXKmPBsQYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Please create me a tweet about going to the park and eating a sandwich.\n",
        "\n",
        "% TONE\n",
        " - Don't use any emojis or hashtags.\n",
        " - Use simple language a 5 year old would understand\n",
        "\"\"\"\n",
        "\n",
        "output = llm.predict(prompt)\n",
        "print (output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "Ch5oq2TZsMnQ",
        "outputId": "2f4a0e57-d37c-4274-f3d5-67d44bf53730"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Mommy and I went to the park today! We brought a yummy sandwich and ate it on a big, cozy blanket. I made a sand castle and played with the ducks. It was the bestest day!\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok cool! The tone has changed. Not bad but now I want it to sound like a specific person. Let's try Bill Gates:\n",
        "\n"
      ],
      "metadata": {
        "id": "0MqHB7CisblK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Please create me a tweet about going to the park and eating a sandwich.\n",
        "\n",
        "% TONE\n",
        " - Don't use any emojis or hashtags.\n",
        " - Respond in the tone of Bill Gates\n",
        "\"\"\"\n",
        "\n",
        "output = llm.predict(prompt)\n",
        "print (output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "EQrkbawIscZI",
        "outputId": "29330d22-294b-401f-a97f-4c8f82b8a1ef"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Today, I ventured to the park and partook in a delightful picnic. As I sunk my teeth into a savory sandwich, the crunch of the bread and the burst of flavors filled my senses. It was a moment of pure bliss, surrounded by nature's beauty. Life's simple pleasures are often the most fulfilling.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's ok, I'd give the response a C+ right now.\n",
        "\n",
        "Let's give some example tweets so the model can better match tone/style.\n",
        "\n",
        "⭐ Important Tip: When you're giving examples, make sure to have the examples the same as the desired output format. Ex: Tweets > Tweets, Email > Email. Don't do Tweets > Email\n",
        "\n"
      ],
      "metadata": {
        "id": "9RDykz_bstSK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method #2: Intermediate - Specify your tone description + examples\n",
        "\n",
        "Examples speak a thousand words. Let's pass a few along with our instructions to see how it goes\n",
        "\n"
      ],
      "metadata": {
        "id": "WyetUafgsyBq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get a users Tweets\n",
        "Next let's grab a users tweets. We'll do this in a function so it's easy to pull them later\n",
        "\n",
        "Since we are live Tweets, you'll need to grather some Twitter api keys. You can get these on the Twitter Developer Portal. The free tier is fine, but watch out for rate limits.\n",
        "\n"
      ],
      "metadata": {
        "id": "zsFQT7GUs2Jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll query 70 tweets because we end up filtering out a bunch, but we'll only return the top 12.\n",
        "# We will also only use a subset of the top tweets later\n",
        "def get_original_tweets(screen_name, tweets_to_pull=20, tweets_to_return=5):\n",
        "\n",
        "    # Tweepy set up\n",
        "    auth = tweepy.OAuthHandler(TWITTER_API_KEY, TWITTER_API_KEY_SECRET)\n",
        "    auth.set_access_token(TWITTER_ACCESS_TOKEN, TWITTER_ACCESS_TOKEN_SECRET)\n",
        "    api = tweepy.API(auth)\n",
        "\n",
        "    tweets = []\n",
        "\n",
        "    tweepy_results = api.user_timeline(screen_name=\"billgates\", count=20)\n",
        "\n",
        "    public_tweets = api.home_timeline()\n",
        "    print(public_tweets)\n",
        "\n",
        "    # tweepy_results = tweepy.Cursor(api.user_timeline,\n",
        "    #                                screen_name=screen_name,\n",
        "    #                                tweet_mode='extended',\n",
        "    #                                exclude_replies=True).items(tweets_to_pull)\n",
        "\n",
        "    # Run through tweets and remove retweets and quote tweets so we can only look at a user's raw emotions\n",
        "    # for status in tweepy_results:\n",
        "    #     if not hasattr(status, 'retweeted_status') and not hasattr(status, 'quoted_status'):\n",
        "    #         tweets.append({'full_text': status.full_text, 'likes': status.favorite_count})\n",
        "\n",
        "\n",
        "    # # Sort the tweets by number of likes. This will help us short_list the top ones later\n",
        "    # sorted_tweets = sorted(tweets, key=lambda x: x['likes'], reverse=True)\n",
        "\n",
        "    # # Get the text and drop the like count from the dictionary\n",
        "    # full_text = [x['full_text'] for x in sorted_tweets][:tweets_to_return]\n",
        "\n",
        "    # # Conver the list of tweets into a string of tweets we can use in the prompt later\n",
        "    # example_tweets = \"\\n\\n\".join(full_text)\n",
        "\n",
        "    return public_tweets\n"
      ],
      "metadata": {
        "id": "HoEPIdYywfYx"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_screen_name = 'billgates'  # Replace this with the desired user's screen name\n",
        "users_tweets = get_original_tweets(user_screen_name)\n",
        "print(users_tweets)\n"
      ],
      "metadata": {
        "id": "-L5pjoMEwrT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## don't have write access.\n",
        "users_tweets ='''\n",
        "These numbers prove why India plays such a crucial role in the world’s fight to improve health, reduce poverty, prevent climate change, and more. https://t.co/xMpmcoYQhi\n",
        "\n",
        "Mann ki Baat has catalyzed community led action on sanitation, health, women’s economic empowerment and other issues linked to the Sustainable Development Goals. Congratulations @narendramodi on the 100th episode. https://t.co/yg1Di2srjE\n",
        "\n",
        "The development of AI is as fundamental as the creation of the microprocessor, the personal computer, the Internet, and the mobile phone. It will change the way people work, learn, travel, get health care, and communicate with each other. https://t.co/uuaOQyxBTl\n",
        "\n",
        "I just returned from my visit to India, and I can’t wait to go back again. I love visiting India because every trip is an incredible opportunity to learn. Here are some photos from my trip and some of the stories behind them: https://t.co/We6PtJWDnp https://t.co/QxZW7gfUmI\n",
        "\n",
        "Superintelligent AIs are in our future. Compared to a computer, our brains operate at a snail’s pace. An electrical signal in the brain moves at ___________ the speed of the signal in a silicon chip. Check your answer here: https://t.co/wqZG1BdoTc\n",
        "\n",
        "Thinking of President Carter and his family. This is a lovely tribute to one of his biggest accomplishments. https://t.co/g53c4ty0qI\n",
        "\n",
        "Uganda’s maternal mortality rate is at least double the global average. That's why Eva Nangalo has dedicated her life to making childbirth in the country safer for everyone involved. https://t.co/29AjdJehNY\n",
        "\n",
        "I am so impressed with Eva Nangalo—it’s hard not to be. She’s spent decades making childbirth safer in Uganda for everyone involved, and she’s become a mentor to countless other midwives in the process. https://t.co/79RHbrCt01\n",
        "\n",
        "I recently had the chance to test drive—or test ride, I guess—one of @wayve_ai’s autonomous vehicles. It was a pretty wild ride: https://t.co/PrwrxU49dd https://t.co/NtnkVx7sBx\n",
        "\n",
        "When I transitioned from @Microsoft to working full-time at the @GatesFoundation, I finally had the time to learn more about physics, chemistry, biology, and other sciences. So, I looked around for the best books and read as many of them as I could find. https://t.co/z2D5xGSeMj\n",
        "\n",
        "As big as the problems facing the world are right now, my visit to India reminded me that our capacity to solve them is even bigger: https://t.co/zp7XfRIpV9 https://t.co/aFHUu987u3\n",
        "\n",
        "I’m grateful for the Lauder family’s dedication to solving Alzheimer’s. https://t.co/vX0qtjBFxt\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "AifyGQ-P4gZn"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pass the tweets as examples\n"
      ],
      "metadata": {
        "id": "1Q4b0wY74twe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "Please create me a tweet about going to the park and eating a sandwich.\n",
        "\n",
        "% TONE\n",
        " - Don't use any emojis or hashtags.\n",
        " - Respond in the tone of Bill Gates\n",
        "\n",
        "% START OF EXAMPLE TWEETS TO MIMIC\n",
        "{example_tweets}\n",
        "% END OF EXAMPLE TWEETS TO MIMIC\n",
        "\n",
        "YOUR TWEET:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"example_tweets\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "final_prompt = prompt.format(example_tweets=users_tweets)\n",
        "\n",
        "print (final_prompt)\n"
      ],
      "metadata": {
        "id": "Ltx9e0KQ4r1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = llm.predict(final_prompt)\n",
        "print (output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "vr5-uw_V42bK",
        "outputId": "66edd527-d7e0-424b-f973-083c6f10a695"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enjoying a delightful afternoon at the park with a scrumptious sandwich, savoring each bite while surrounded by nature's beauty. #PeacefulHarmony #SimplePleasures\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wow! Ok now that is starting to get somewhere. Not bad at all! Sounds like Bill is in the room with us now.\n",
        "\n",
        "Let's see if we can refine it even more.\n",
        "\n"
      ],
      "metadata": {
        "id": "E7QLntvM5ELr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method #3: AI-Assisted: Ask the LLM help with tone descriptions\n",
        "\n",
        "Turns out I'm not great at describing tone. Examples are a good way to help, but can we do more? Let's find out.\n",
        "\n",
        "I want to have the model tell me what tone it sees, then use that output as an input to the final prompt where I ask it to generate a tweet.\n",
        "\n",
        "Almost like reverse engineering tone.\n",
        "\n",
        "Why don't I do this all in one step? You likely could, but it would be nice to save this \"tone\" description for future use. Plus, I don't want the model to take too many logic jumps in a single response.\n",
        "\n",
        "I first thought, 'well... what are the qualities of tone I should have it describe?'\n",
        "\n",
        "Then I thought, Greg, c'mon man, you know better than that, see if the LLM has a good sense of what tone qualities there are. Duh.\n",
        "\n",
        "Let's see what are the qualities of tone we should extract\n",
        "\n"
      ],
      "metadata": {
        "id": "EdFX3Q815E-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Can you please generate a list of tone attributes and a description to describe a piece of writing by? please include example also.\n",
        "\n",
        "Things like pace, mood, etc.\n",
        "\n",
        "Respond with nothing else besides the list\n",
        "\"\"\"\n",
        "\n",
        "how_to_describe_tone = llm.predict(prompt)\n",
        "print (how_to_describe_tone)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "na_V0vti5_1g",
        "outputId": "3694d90d-43e0-41b9-ebb8-5f5d9fc7a8bc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **Tone:** The overall emotional atmosphere of a piece of writing.\n",
            "- **Mood:** The emotional state that the reader is left with after reading a piece of writing.\n",
            "- **Pace:** The speed at which a piece of writing moves.\n",
            "- **Rhythm:** The flow and cadence of a piece of writing.\n",
            "- **Voice:** The personality of the writer as expressed through their writing.\n",
            "- **Diction:** The word choice of a writer.\n",
            "- **Syntax:** The structure of a sentence or phrase.\n",
            "- **Figurative Language:** The use of words or phrases that create a vivid image or idea in the reader's mind.\n",
            "- **Imagery:** The use of words or phrases that create a sensory experience for the reader.\n",
            "- **Symbolism:** The use of objects, characters, or actions to represent something else.\n",
            "- **Allusion:** The reference to a well-known person, place, thing, or event.\n",
            "- **Irony:** The use of words or situations to create a contrast between what is expected and what actually happens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_authors_tone_description(how_to_describe_tone, users_tweets):\n",
        "    template = \"\"\"\n",
        "        You are an AI Bot that is very good at generating writing in a similar tone as examples.\n",
        "        Be opinionated and have an active voice.\n",
        "        Take a strong stance with your response.\n",
        "\n",
        "        % HOW TO DESCRIBE TONE\n",
        "        {how_to_describe_tone}\n",
        "\n",
        "        % START OF EXAMPLES\n",
        "        {tweet_examples}\n",
        "        % END OF EXAMPLES\n",
        "\n",
        "        List out the tone qualities of the examples above\n",
        "        \"\"\"\n",
        "\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"how_to_describe_tone\", \"tweet_examples\"],\n",
        "        template=template,\n",
        "    )\n",
        "\n",
        "    final_prompt = prompt.format(how_to_describe_tone=how_to_describe_tone, tweet_examples=users_tweets)\n",
        "\n",
        "    authors_tone_description = llm.predict(final_prompt)\n",
        "\n",
        "    return authors_tone_description\n"
      ],
      "metadata": {
        "id": "6YXSyM128p5O"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "authors_tone_description = get_authors_tone_description(how_to_describe_tone, users_tweets)\n",
        "print (authors_tone_description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "JGaMTMIq84pg",
        "outputId": "d007e284-9a5e-4cdf-801c-bc29e8265fa2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- **Informative**: The examples provide information on various topics such as India's role in global development, the impact of Mann ki Baat, the significance of AI, and the work of Eva Nangalo in improving maternal health in Uganda.\n",
            "\n",
            "\n",
            "- **Engaging**: The examples use personal anecdotes, vivid descriptions, and interactive elements to capture the reader's attention and make the content more relatable.\n",
            "\n",
            "\n",
            "- **Optimistic**: The examples convey a positive outlook on the world and highlight the potential for progress and solutions to global challenges.\n",
            "\n",
            "\n",
            "- **Thought-provoking**: The examples encourage readers to think critically about important issues and consider different perspectives.\n",
            "\n",
            "\n",
            "- **Inspiring**: The examples showcase the work of individuals and organizations that are making a positive impact on the world, inspiring readers to take action and contribute to global progress.\n",
            "\n",
            "\n",
            "- **Passionate**: The examples reflect the author's strong beliefs and commitment to addressing global issues, conveying a sense of urgency and importance.\n",
            "\n",
            "\n",
            "- **Conversational**: The examples use a conversational tone, making the content feel like a dialogue between the author and the reader, fostering a sense of connection and relatability.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great, now that we have Bill Gate's tone style, let's put those tone instructions in with the prompt we had before to see if it helps\n",
        "\n"
      ],
      "metadata": {
        "id": "Z8pbsg9r_Sbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "% INSTRUCTIONS\n",
        " - You are an AI Bot that is very good at mimicking an author writing style.\n",
        " - Your goal is to write content with the tone that is described below.\n",
        " - Do not go outside the tone instructions below\n",
        " - Do not use hashtags or emojis\n",
        " - Respond in the tone of Bill Gates\n",
        "\n",
        "% Description of the authors tone:\n",
        "{authors_tone_description}\n",
        "\n",
        "% Authors writing samples\n",
        "{tweet_examples}\n",
        "\n",
        "% YOUR TASK\n",
        "Please create a tweet about going to the park and eating a sandwich.\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"authors_tone_description\", \"tweet_examples\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "final_prompt = prompt.format(authors_tone_description=authors_tone_description, tweet_examples=users_tweets)\n",
        "llm.predict(final_prompt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "1NZ9EAol_WGH",
        "outputId": "d1804096-14ef-4e7b-fd33-385b52c86072"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Just spent a delightful day at the park, basking in the sunshine and breathing in the fresh air. Enjoyed a delightful picnic lunch, savoring every bite of my sandwich while surrounded by nature's beauty. It's these simple moments that truly enrich life. #ParkBliss #NatureLovers\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hmm, better! Not wonderful.\n",
        "\n",
        "Let's try out the final approach\n",
        "\n"
      ],
      "metadata": {
        "id": "ERBbtm4r_lRb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method 4 - Technique Fusion: Combine multiple techniques to mimic tone\n",
        "After a lot of experimentation I've found the below tips to be helpful\n",
        "\n",
        "**Don't reference the word 'tweet' in your prompt** - The model has an extremely strong bias towards what a 'tweet' is an will overload you with hashtags and emojis. Rather call it \"a short public statement around 300 characters\"\n",
        "\n",
        "**Ask the LLM for similar sounding authors** - Whereas model bias on the word 'tweet' (point #1) isn't great, we can use it in our favor. Ask the LLM which authors the writing style sounds like, then ask the LLM to respond like that author. It's not great that the model is basing the tone off another person but it's a great 89% solution. I learned of this technique from Scott Mitchell.\n",
        "Examples should be in the output format you want - Everyone has a different voice. Twitter voice, email voice etc. Make sure that the examples you feed to the prompt are the same voice as the output you want. Ex: Don't exect a book to be written from twitter examples.\n",
        "\n",
        "**Use the Language Model to extract tone** - If you are at a loss for words on how to describe the tone you want, have the language model describe it for you. I found I needed to tell the model to be opinionated, it was too grey-area before.\n",
        "\n",
        "**Topics matter** - Have the model propose topics first, then give you a tweet. Not only is it better to have things the author would actually talk about, but it's also really good to keep the model on track by having it outline the topics first then respond\n",
        "\n",
        "Let's first identify authors the model thinks the example tweets sound like, then we'll reference those later. Keep in mind this isn't a true classification exercise and the point isn't to be 100% correct on similar people, it's to get a reference to who the model thinks is similar so we can use that inuition for instructions later.\n",
        "\n"
      ],
      "metadata": {
        "id": "CKJCS2VfCAM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_similar_public_figures(tweet_examples):\n",
        "    template = \"\"\"\n",
        "    You are an AI Bot that is very good at identifying authors, public figures, or writers whos style matches a piece of text\n",
        "    Your goal is to identify which authors, public figures, or writers sound most similar to the text below\n",
        "\n",
        "    % START EXAMPLES\n",
        "    {tweet_examples}\n",
        "    % END EXAMPLES\n",
        "\n",
        "    Which authors (list up to 1 if necessary) most closely resemble the examples above? Only respond with the names separated by commas\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"tweet_examples\"],\n",
        "        template=template,\n",
        "    )\n",
        "\n",
        "    # Using the short list of examples so save on tokens and (hopefully) the top tweets\n",
        "    final_prompt = prompt.format(tweet_examples=tweet_examples)\n",
        "\n",
        "    authors = llm.predict(final_prompt)\n",
        "    return authors\n"
      ],
      "metadata": {
        "id": "aVqc74WGCZ2w"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "authors = get_similar_public_figures(users_tweets)\n",
        "print (authors)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Gqy7PKx7Chls",
        "outputId": "c797f068-35b0-4ab3-dccf-596ef6f9e1b5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bill Gates\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok that's not that exciting! Becuase we used Bill Gates' example tweets. Trust me that it's better with less-known people. We'll try this more later.\n",
        "\n",
        "At last, the final output. Let's bring it all together in a single prompt. Notice the 2 step process in the \"your task\" section below\n",
        "\n"
      ],
      "metadata": {
        "id": "EQK5uEUJETJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "% INSTRUCTIONS\n",
        " - You are an AI Bot that is very good at mimicking an author writing style.\n",
        " - Your goal is to write content with the tone that is described below.\n",
        " - Do not go outside the tone instructions below\n",
        "\n",
        "% Mimic These Authors:\n",
        "{authors}\n",
        "\n",
        "% Description of the authors tone:\n",
        "{tone}\n",
        "\n",
        "% Authors writing samples\n",
        "{example_text}\n",
        "% End of authors writing samples\n",
        "\n",
        "% YOUR TASK\n",
        "1st - Write out topics that this author may talk about\n",
        "2nd - Write a concise passage (under 300 characters) as if you were the author described above\n",
        "\"\"\"\n",
        "\n",
        "method_4_prompt_template = PromptTemplate(\n",
        "    input_variables=[\"authors\", \"tone\", \"example_text\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "# Using the short list of examples so save on tokens and (hopefully) the top tweets\n",
        "final_prompt = method_4_prompt_template.format(authors=authors,\n",
        "                                               tone=authors_tone_description,\n",
        "                                               example_text=users_tweets)\n"
      ],
      "metadata": {
        "id": "WamfaXFaEUlc"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = llm.predict(final_prompt)\n",
        "print (output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "dNDysrWVEbwy",
        "outputId": "54454284-7df4-44e6-b233-6d04405df67a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Topics:**\n",
            "\n",
            "- Global development and poverty reduction\n",
            "- Healthcare and maternal health\n",
            "- Education and technology\n",
            "- Climate change and sustainability\n",
            "- Artificial Intelligence and its impact on society\n",
            "- Philanthropy and social responsibility\n",
            "- Inspirational stories of individuals making a positive impact\n",
            "- Sustainable Development Goals and the role of India\n",
            "\n",
            "**Passage:**\n",
            "\n",
            "\"Innovation and collaboration are key to tackling global challenges. From AI shaping industries to community-led initiatives transforming lives, each step forward brings us closer to a brighter future for all.\"\n"
          ]
        }
      ]
    }
  ]
}